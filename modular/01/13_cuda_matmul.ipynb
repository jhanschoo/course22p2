{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas before we vectorized away the innermost loop of matmul, in this version we first focus on parallelizing the outer loops that iterae through the entries of the target array. Each invocation accepts a `grid = (i, j)` parameter to indicate the target coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def matmul(grid, a, b, c):\n",
    "    i, j = grid\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]):\n",
    "            tmp += a[i, k] * b[k, j]\n",
    "        c[i,j] = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "pickle_path = URLs.path('mnist_png')/'mnist_png.pkl'\n",
    "path = untar_data(URLs.MNIST)/'training'\n",
    "\n",
    "if not pickle_path.exists():\n",
    "    pickle_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    ds = DataBlock(\n",
    "        blocks = (ImageBlock(PILImageBW), CategoryBlock),\n",
    "        get_items = get_image_files,\n",
    "        get_y = parent_label,\n",
    "        splitter = RandomSplitter(1/6, seed=0)\n",
    "    ).datasets(path)\n",
    "\n",
    "    xs, ys = zip(*ds.train, *ds.valid)\n",
    "    xs = np.stack(L(map(lambda x: np.array(x, dtype=np.float32).reshape(-1), xs))) / 255.\n",
    "    ys = np.array(ys, dtype=np.int64)\n",
    "\n",
    "    x_train, x_valid = xs[:len(ds.train)], xs[len(ds.train):]\n",
    "    y_train, y_valid = ys[:len(ds.train)], ys[len(ds.train):]\n",
    "\n",
    "    save_pickle(pickle_path, [x_train, y_train, x_valid, y_valid])\n",
    "\n",
    "    del ds, xs, ys, x_train, y_train, x_valid, y_valid\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, load_pickle(pickle_path))\n",
    "\n",
    "torch.manual_seed(1)\n",
    "weights = torch.randn(784, 10)\n",
    "bias = torch.zeros(10)\n",
    "\n",
    "m1 = x_valid[:5]\n",
    "m2 = weights\n",
    "ar, ac = m1.shape \n",
    "br, bc = m2.shape\n",
    "\n",
    "t1 = torch.zeros(ar, bc)\n",
    "\n",
    "for i in range(ar):         # 5\n",
    "    for j in range(bc):     # 10\n",
    "        for k in range(ac): # 784\n",
    "            t1[i, j] += m1[i, k] * m2[k, j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.8318,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.zeros(ar, bc)\n",
    "matmul((0, 0), m1, m2, res)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a harness for calling `matmul` on each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n",
    "    for i in range(grid_x):\n",
    "        for j in range(grid_y):\n",
    "            kernel((i, j), *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give it a go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -7.8318,  -9.3646,   6.0571, -14.2204,  20.7075,   1.9792, -20.8511,\n",
       "         -14.9247, -24.9726,  -1.5234],\n",
       "        [  9.5953,   8.4150,   8.4275,  -7.7321,  11.0846, -26.4744,  -3.6933,\n",
       "          -9.4670, -35.0040,   7.3345],\n",
       "        [  4.7560,  -3.3547,  -8.8216,  11.5083,  -5.3496,  -2.2799, -14.0786,\n",
       "           1.3523,  -7.9863,  -3.3055],\n",
       "        [  6.8275,   1.2459,  -0.5831,  13.8737,  -1.6997,  -7.8282,  -1.4413,\n",
       "           0.4070, -17.4009,  -7.7779],\n",
       "        [-11.6686, -12.9786,  -7.4251,  -4.4291,  -1.6932,   3.1152,  -5.8956,\n",
       "          -5.2578, -15.3839,   3.5509]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.zeros(ar, bc)\n",
    "launch_kernel(matmul, ar, bc, m1, m2, res)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `cuda.jit`, the indices are provided by `cuda.grid(2)`. In general, the GPU may attempt to evaluate the function beyond the shape of `c`, so we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(a,b,c):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n",
    "        c[i,j] = tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the testing environment, and send all the relevant tensors to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tr = x_train @ weights\n",
    "r = np.zeros(tr.shape)\n",
    "m1g, m2g, rg = map(cuda.to_device, (x_train, weights, r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall execute 16 x 16 threads for each CUDA block, and compute the number of blocks in each direction that we shall use. If `c` has shape strictly smaller than `blocks * TPB`, then `matmul` will be run on invalid indices, hence the bounds checking in our definition previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "TPB = 16\n",
    "rr, rc = r.shape\n",
    "blocks = (math.ceil(rr / TPB), math.ceil(rc / TPB))\n",
    "blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "matmul[blocks, (TPB, TPB)](m1g, m2g, rg)\n",
    "r = rg.copy_to_host()\n",
    "test_close(tr, r, eps=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.68 ms ± 315 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "matmul[blocks, (TPB, TPB)](m1g, m2g, rg)\n",
    "r = rg.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the speed of the inbuilt `matmul` of PyTorch on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "m1c, m2c = x_train.cuda(), weights.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "r = (m1c @ m2c).cpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing performance; we observe a close to 10x speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 µs ± 158 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 r = (m1c @ m2c).cpu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
